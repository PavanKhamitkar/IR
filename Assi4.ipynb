{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment - 04\n",
        "+ Implementing the PageRank Algorithm"
      ],
      "metadata": {
        "id": "0tZuux3Vl3FK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGhlUPg5l0LY",
        "outputId": "afe180eb-8125-44dc-f992-6bdf349ef2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PageRank Values:\n",
            "URL: https://pll.harvard.edu/subject/data-science, PageRank: 0.2500\n",
            "URL: https://www.ibm.com/topics/data-science, PageRank: 0.2500\n",
            "URL: https://www.coursera.org/specializations/jhu-data-science, PageRank: 0.2500\n",
            "URL: https://www.youtube.com/watch?v=GhFgnkLPZj4, PageRank: 0.2500\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_html(url):\n",
        "    \"\"\"Fetch HTML content from a URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad responses\n",
        "        return response.text\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_html(html_content):\n",
        "    \"\"\"Parse HTML content and extract links.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    links = []\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        href = a['href']\n",
        "        # Skip links that do not start with \"http\" to avoid relative URLs\n",
        "        if href.startswith('http'):\n",
        "            links.append(href)\n",
        "    return links\n",
        "\n",
        "def build_graph(urls):\n",
        "    \"\"\"Build a directed graph based on the links between the given URLs.\"\"\"\n",
        "    graph = nx.DiGraph()\n",
        "\n",
        "    # Fetch HTML content and add nodes and edges to the graph\n",
        "    for url in urls:\n",
        "        html_content = fetch_html(url)\n",
        "        if html_content:\n",
        "            graph.add_node(url)  # Add the URL as a node\n",
        "            links = parse_html(html_content)\n",
        "            for link in links:\n",
        "                if link in urls:  # Only add links that are in the provided list of URLs\n",
        "                    graph.add_edge(url, link)  # Create a directed edge from URL to link\n",
        "\n",
        "    return graph\n",
        "\n",
        "def calculate_pagerank(graph):\n",
        "    \"\"\"Calculate PageRank for the nodes in the graph.\"\"\"\n",
        "    page_ranks = nx.pagerank(graph)\n",
        "    return page_ranks\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # List of URLs to analyze (adjust the URLs as needed)\n",
        "    urls_to_analyze = [\n",
        "        'https://pll.harvard.edu/subject/data-science',\n",
        "        'https://www.ibm.com/topics/data-science',\n",
        "        'https://www.coursera.org/specializations/jhu-data-science',\n",
        "        'https://www.youtube.com/watch?v=GhFgnkLPZj4',\n",
        "        'https://pll.harvard.edu/subject/data-science',\n",
        "        'https://www.ibm.com/topics/data-science',\n",
        "        'https://www.ibm.com/topics/data-science','https://www.ibm.com/topics/data-science',\n",
        "    ]\n",
        "\n",
        "    # Step 1: Build the graph\n",
        "    web_graph = build_graph(urls_to_analyze)\n",
        "\n",
        "    # Step 2: Calculate the PageRank\n",
        "    pagerank_values = calculate_pagerank(web_graph)\n",
        "\n",
        "    # Step 3: Display the results\n",
        "    print(\"PageRank Values:\")\n",
        "    for url, rank in pagerank_values.items():\n",
        "        print(f\"URL: {url}, PageRank: {rank:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhYcu5qbnt4J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}